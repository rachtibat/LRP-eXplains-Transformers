import matplotlib.cm as cm
import matplotlib.colors as colors
import os
import subprocess
from pathlib import Path

def _apply_colormap(relevance, cmap):
    
    colormap = cm.get_cmap(cmap)
    return colormap(colors.Normalize(vmin=-1, vmax=1)(relevance))

def _generate_latex(words, relevances, cmap="bwr"):
    """
    Generate LaTeX code for a sentence with colored words based on their relevances.
    """

    # Generate LaTeX code
    latex_code = r'''
    \documentclass[arwidth=200mm]{standalone} 
    \usepackage[dvipsnames]{xcolor}
    
    \begin{document}
    \fbox{
    \parbox{\textwidth}{
    \setlength\fboxsep{0pt}
    '''

    for word, relevance in zip(words, relevances):
        rgb = _apply_colormap(relevance, cmap)
        r, g, b = int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255)

        if word.startswith(' '):
            latex_code += f' \\colorbox[RGB]{{{r},{g},{b}}}{{\\strut {word}}}'
        else:
            latex_code += f'\\colorbox[RGB]{{{r},{g},{b}}}{{\\strut {word}}}'


    latex_code += r'}}\end{document}'

    return latex_code

    
def _compile_latex_to_pdf(latex_code, path='word_colors.pdf', delete_aux_files=True, backend='xelatex'):
    """
    Compile LaTeX code to a PDF file using pdflatex or xelatex.
    """
    
    # Save LaTeX code to a file
    path = Path(path)
    os.makedirs(path.parent, exist_ok=True)

    with open(path.with_suffix(".tex"), 'w') as f:
        f.write(latex_code)

    # Use pdflatex to generate PDF file
    if backend == 'pdflatex':
        subprocess.call(['pdflatex', '--output-directory', path.parent, path.with_suffix(".tex")])
    elif backend == 'xelatex':
        subprocess.call(['xelatex', '--output-directory', path.parent, path.with_suffix(".tex")])

    print("PDF file generated successfully.")

    if delete_aux_files:
        for suffix in ['.aux', '.log', '.tex']:
            os.remove(path.with_suffix(suffix))


def pdf_heatmap(words, relevances, cmap="bwr", path='heatmap.pdf', delete_aux_files=True, backend='xelatex'):
    """
    Generate a PDF file with a heatmap of the relevances of the words in a sentence using LaTeX.

    Parameters
    ----------
    words : list of str
        The words in the sentence.
    relevances : list of float
        The relevances of the words normalized between -1 and 1.
    cmap : str
        The name of the colormap to use.
    path : str
        The path to save the PDF file.
    delete_aux_files : bool
        Whether to delete the auxiliary files generated by LaTeX.
    backend : str
        The LaTeX backend to use (pdflatex or xelatex).
    """

    assert len(words) == len(relevances), "The number of words and relevances must be the same."
    assert relevances.min() >= -1 and relevances.max() <= 1, "The relevances must be normalized between -1 and 1."

    latex_code = _generate_latex(words, relevances, cmap=cmap)
    _compile_latex_to_pdf(latex_code, path=path, delete_aux_files=delete_aux_files, backend=backend)


def clean_tokens(words):
    """
    Clean wordpiece tokens by removing special characters and splitting them into words.
    """

    if any("▁" in word for word in words):
        words = [word.replace("▁", " ") for word in words]
    
    elif any("Ġ" in word for word in words):
        words = [word.replace("Ġ", " ") for word in words]
    
    elif any("##" in word for word in words):
        words = [word.replace("##", "") if "##" in word else " " + word for word in words]
        words[0] = words[0].strip()

    else:
        raise ValueError("The tokenization scheme is not recognized.")
    
    special_characters = ['&', '%', '$', '#', '_', '{', '}', '\\']
    for i, word in enumerate(words):
        for special_character in special_characters:
            if special_character in word:
                words[i] = word.replace(special_character, '\\' + special_character)

    return words

